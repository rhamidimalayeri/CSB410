{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5554cb5d",
   "metadata": {},
   "source": [
    "# Lab 9\n",
    "\n",
    "— Generative Adversarial Networks (GANs)\n",
    "\n",
    "Build and train a **vanilla GAN** using the exact building blocks shown in the reference script:\n",
    "\n",
    "- `9-generative_adversarial_network.ipynb`\n",
    "  and concepts from the slides: `9 - GANs.pptx`.\n",
    "\n",
    "Each task below includes **explicit steps**, **where to find matching content** in the script, and the **expected output**.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/username/repo/blob/main/path-to-file)  \n",
    "**Students:** Replace `username`, `repo`, and `path-to-file` with your own GitHub username, repository name, and the path to this file.  \n",
    "After opening in Colab, go to **File → Save a copy to GitHub** (your repo) before editing.\n",
    "\n",
    "#### NOTE: You will need to use a GPU on Google Colab for this to run in a reasonable amount of time without memory running out. I suggest using A100 GPU. Edit -> Notebook Settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17909278",
   "metadata": {},
   "source": [
    "## H.1 Data Preparation — MNIST 28×28 Grayscale\n",
    "\n",
    "**Reference script:** `9-generative_adversarial_network.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c6e4e",
   "metadata": {},
   "source": [
    "**Where to find in the script:**\n",
    "\n",
    "- Imports and dataset load → near the top cells (look for `keras.datasets.mnist.load_data()` and normalization step).\n",
    "- Reshaping to `(N, 28, 28, 1)` and scaling to `[0,1]` → the preprocessing cell after load.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (H.1): Load MNIST, scale to [0,1], and reshape to (N,28,28,1).\n",
    "# Steps:\n",
    "# 1) Use keras.datasets.mnist.load_data()\n",
    "# 2) Convert to float32 and divide by 255.0\n",
    "# 3) Expand dims to add channel axis\n",
    "# Output variables: x_train (float32, shape=(60000,28,28,1))\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12a03d",
   "metadata": {},
   "source": [
    "**Expected output (H.1):**\n",
    "\n",
    "- `x_train.shape == (60000, 28, 28, 1)`\n",
    "- `x_train.min() >= 0.0` and `x_train.max() <= 1.0`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454848c1",
   "metadata": {},
   "source": [
    "## H.2 Define the Discriminator\n",
    "\n",
    "**Reference script:** `9-generative_adversarial_network.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf8e9b4",
   "metadata": {},
   "source": [
    "**Where to find in the script:**\n",
    "\n",
    "- Discriminator block → look for a `Sequential` with Conv2D → LeakyReLU → Dropout stacks and a final Dense(1,'sigmoid').\n",
    "- Optimizer setup for discriminator (often Adam with β1≈0.5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (H.2): Build the discriminator.\n",
    "# Architecture (match script style):\n",
    "#   Input: (28,28,1)\n",
    "#   Conv2D(64, kernel_size=5, strides=2, padding='same') → LeakyReLU(0.2) → Dropout(0.3)\n",
    "#   Conv2D(128, kernel_size=5, strides=2, padding='same') → LeakyReLU(0.2) → Dropout(0.3)\n",
    "#   Flatten → Dense(1, activation='sigmoid')\n",
    "# Compile with loss='binary_crossentropy', optimizer=Adam(lr ~ 2e-4, beta_1 ~ 0.5), metrics=['accuracy']\n",
    "# Name your model variable: discriminator\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b06db9",
   "metadata": {},
   "source": [
    "**Expected output (H.2):**\n",
    "\n",
    "- `discriminator` is a compiled Keras model.\n",
    "- Calling `discriminator(tf.zeros([1,28,28,1]))` returns a (1,1) tensor in [0,1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2639125f",
   "metadata": {},
   "source": [
    "## H.3 Define the Generator\n",
    "\n",
    "**Reference script:** `9-generative_adversarial_network.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f2967b",
   "metadata": {},
   "source": [
    "**Where to find in the script:**\n",
    "\n",
    "- Generator block → look for Dense → Reshape → Conv2DTranspose stacks finishing with sigmoid.\n",
    "- Latent vector size (e.g., `latent_dim = 100`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f499ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (H.3): Build the generator that maps z∼N(0,1) of shape (latent_dim,) to (28,28,1).\n",
    "# Suggested pattern (match script):\n",
    "#   Dense(7*7*128) → LeakyReLU → Reshape(7,7,128)\n",
    "#   Conv2DTranspose(64, kernel_size=5, strides=2, padding='same') → LeakyReLU\n",
    "#   Conv2DTranspose(1,  kernel_size=5, strides=2, padding='same', activation='sigmoid')\n",
    "# Name your model variable: generator\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc609b4",
   "metadata": {},
   "source": [
    "**Expected output (H.3):**\n",
    "\n",
    "- `generator` is a Keras model that, given a (batch, latent_dim) noise input, outputs images of shape (batch,28,28,1) in [0,1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5dedf8",
   "metadata": {},
   "source": [
    "## H.4 Adversarial (GAN) Model\n",
    "\n",
    "**Reference script:** `9-generative_adversarial_network.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc8633",
   "metadata": {},
   "source": [
    "**Where to find in the script:**\n",
    "\n",
    "- Code that freezes the discriminator (`discriminator.trainable = False`) and builds a `gan = Model(z, discriminator(generator(z)))`.\n",
    "- Optimizer for GAN (often same Adam params).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b255e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (H.4): Build the GAN by stacking generator → discriminator.\n",
    "# Steps:\n",
    "# 1) Set discriminator.trainable = False (for the GAN compile step)\n",
    "# 2) Create an Input for z (latent_dim,)\n",
    "# 3) Pass through generator then discriminator\n",
    "# 4) Compile GAN with loss='binary_crossentropy' and Adam(lr ~ 2e-4, beta_1 ~ 0.5)\n",
    "# Name your model variable: gan\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd1e89",
   "metadata": {},
   "source": [
    "**Expected output (H.4):**\n",
    "\n",
    "- `gan` is a compiled model that takes noise and returns a real/fake score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6cb8a7",
   "metadata": {},
   "source": [
    "## H.5 Training Loop (Memory-aware)\n",
    "\n",
    "**Reference script:** `9-generative_adversarial_network.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a98a2fb",
   "metadata": {},
   "source": [
    "**Where to find in the script:**\n",
    "\n",
    "- The custom loop alternating discriminator and generator updates (often using real labels=1 and fake labels=0).\n",
    "- Epoch logging and periodic sampling of generated images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c39c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (H.5): Implement the training loop.\n",
    "# Memory-safe defaults:\n",
    "#   BATCH = 64 on strong GPUs, otherwise start at 32 or 16. If OOM, reduce further.\n",
    "#   EPOCHS = 30 (OK for class); to speed up, set 10–15.\n",
    "# Steps per epoch ~ len(x_train)//BATCH.\n",
    "# Steps per training step:\n",
    "#   a) Sample real batch from x_train → label=1\n",
    "#   b) Sample noise, generate fake batch → label=0\n",
    "#   c) Train discriminator on real then on fake; average the two losses.\n",
    "#   d) Train GAN (freeze D) with noise and label=1 (generator tries to fool D).\n",
    "#   e) Every N epochs: generate 4×4 image grid.\n",
    "\n",
    "# IMPORTANT: Experiment with epochs and other hyperparameters to try to get the best results.\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961fdb6f",
   "metadata": {},
   "source": [
    "**Expected output (H.5):**\n",
    "\n",
    "- Per-epoch logs: D loss/acc and GAN (generator) loss.\n",
    "- A few image grids showing samples improving over time.\n",
    "- Final print of losses across epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3759fcd",
   "metadata": {},
   "source": [
    "## Discussion Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bafd4f",
   "metadata": {},
   "source": [
    "1. Why can GAN training be unstable? Name two symptoms and one stabilization trick.\n",
    "2. What happens if the discriminator is much stronger than the generator? How would you adjust training?\n",
    "3. If generated digits are blurry, which change to the generator would you try first, and why?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
