{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f34b74",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/username/repo/blob/main/path-to-file)  \n",
    "**Students:** Replace `username`, `repo`, and `path-to-file` with your own GitHub username, repository name, and the path to this file.  \n",
    "After opening in Colab, go to **File → Save a copy to GitHub** (your repo) before editing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe37d6",
   "metadata": {},
   "source": [
    "# Lab 6 (Week 7) — Convolutional Neural Networks (CNNs) — Student v4\n",
    "\n",
    "This lab maps directly to your Week 7 notebooks:\n",
    "\n",
    "- `7-lenet_in_keras.ipynb`\n",
    "- `7-alexnet_in_keras.ipynb`\n",
    "- `7-transfer_learning_in_keras.ipynb`\n",
    "\n",
    "**Sections**\n",
    "\n",
    "- F.1 LeNet-5 style CNN in Keras (MNIST)\n",
    "- F.2 AlexNet-like CNN in Keras (small image dataset, e.g., CIFAR-10)\n",
    "- F.3 Transfer Learning & Fine-Tuning with a Pretrained CNN\n",
    "\n",
    "#### NOTE: You will need to use a GPU on Google Colab for this to run in a reasonable amount of time without memory running out. I suggest using A100 GPU. Edit -> Notebook Settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125015b",
   "metadata": {},
   "source": [
    "## F.1 LeNet-5 Style CNN (Keras, MNIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fd3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions only — write your own code. Reference: 7-lenet_in_keras.ipynb\n",
    "# Goal: Build and train a small LeNet-style CNN on MNIST.\n",
    "#\n",
    "# What to do:\n",
    "# 1) Load MNIST via keras.datasets; normalize to [0,1]; reshape to (N,28,28,1).\n",
    "# 2) Build a LeNet-style model, e.g.:\n",
    "#       Conv2D(32,(5,5),activation='relu') -> MaxPool2D(2,2)\n",
    "#       Conv2D(64,(5,5),activation='relu') -> MaxPool2D(2,2)\n",
    "#       Flatten -> Dense(120,'relu') -> Dense(84,'relu') -> Dense(10,'softmax')\n",
    "# 3) Compile: optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'].\n",
    "# 4) Train 2–3 epochs (validation_split=0.1, batch_size=128).\n",
    "# 5) Evaluate on test set; print test accuracy. Also print model.summary().\n",
    "#\n",
    "# Hints:\n",
    "# - Follow the exact preprocessing and layer pattern in 7-lenet_in_keras.ipynb.\n",
    "# - If your script used tanh/sigmoid, keep consistent unless instructed otherwise.\n",
    "#\n",
    "# Expected output:\n",
    "# - A model summary (Conv/Pool layers followed by Dense layers).\n",
    "# - Test accuracy typically ≥ 0.98 after a few epochs.\n",
    "# My final accuracy was: {'mnist_test_accuracy': 0.9850999712944031, 'mnist_test_loss': 0.04505486041307449}\n",
    "# yours should be similar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbf378",
   "metadata": {},
   "source": [
    "## F.2 AlexNet-like CNN (Keras, Small Image Dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da210f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions only — write your own code. Reference: 7-alexnet_in_keras.ipynb\n",
    "# Goal: Adapt an AlexNet-like architecture to a smaller dataset (e.g., CIFAR-10).\n",
    "#\n",
    "# What to do:\n",
    "# 1) Choose dataset (e.g., CIFAR-10). Normalize images to [0,1]; ensure shape (N,H,W,3).\n",
    "# 2) Build an AlexNet-like model. Example skeleton (downscaled for small images):\n",
    "#       Conv2D(64,(3,3),strides=1,activation='relu',padding='same')\n",
    "#       MaxPool2D(2,2)\n",
    "#       Conv2D(192,(3,3),activation='relu',padding='same')\n",
    "#       MaxPool2D(2,2)\n",
    "#       Conv2D(384,(3,3),activation='relu',padding='same')\n",
    "#       Conv2D(256,(3,3),activation='relu',padding='same')\n",
    "#       Conv2D(256,(3,3),activation='relu',padding='same')\n",
    "#       MaxPool2D(2,2)\n",
    "#       Flatten -> Dense(1024,'relu') -> Dropout(0.5)\n",
    "#                -> Dense(1024,'relu') -> Dropout(0.5)\n",
    "#                -> Dense(num_classes,'softmax')\n",
    "# 3) Compile with Adam(1e-3), loss='sparse_categorical_crossentropy'.\n",
    "# 4) Train ~3 epochs (validation_split=0.1, batch_size=128); print test accuracy and model.summary().\n",
    "#\n",
    "# Hints:\n",
    "# - See layer ordering and hyperparameters in 7-alexnet_in_keras.ipynb.\n",
    "# - Adjust kernel sizes/strides for small images as shown in the script.\n",
    "#\n",
    "# Expected output:\n",
    "# - Model summary showing stacked conv blocks and large dense layers.\n",
    "# - Test accuracy after a few epochs (values vary; short runs ~0.65–0.80 on CIFAR-10).\n",
    "# My final accuracy was: {'cifar10_test_accuracy': 0.7612000107765198, 'cifar10_test_loss': 0.7743515968322754}\n",
    "# Yours should be similar or better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc626ba",
   "metadata": {},
   "source": [
    "## F.3 Transfer Learning & Fine-Tuning (Pretrained CNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d49c074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions only — write your own code. Reference: 7-transfer_learning_in_keras.ipynb\n",
    "# Goal: Use a pretrained ImageNet model as a feature extractor, then fine-tune.\n",
    "#\n",
    "# What to do:\n",
    "#\t1.\tPick a pretrained base (MobileNetV2) exactly as in the reference script, with weights='imagenet', include_top=False, and input_shape=(224,224,3).\n",
    "#\t2.\tPreprocess your inputs using the matching keras.applications.mobilenet_v2.preprocess_input.\n",
    "#\t3.\tBuild a classification head: GlobalAveragePooling2D → Dense(num_classes,'softmax').\n",
    "#\t4.\tFreeze the base; train the head for 2–3 epochs (we’ll default to 3).\n",
    "#\t5.\tUnfreeze top blocks (e.g., last 20–30 layers) and fine-tune with a low learning rate (e.g., 1e-5) for 1–2 epochs (we’ll default to 2).\n",
    "#\t6.\tPrint train/val accuracy each epoch and a final test accuracy line.\n",
    "#\n",
    "# Memory & batch size rules (important)\n",
    "#\t•\tStart with BATCH_SIZE = 32 on moderate GPUs/CPUs.\n",
    "#\t•\tIf you hit OOM (out-of-memory) or Colab aborts, reduce batch size to 16 → 8 → 4.\n",
    "#\t•\tIf your GPU is weak (e.g., T4) or you’re on CPU, consider reducing IMG_SIZE to 160 (or 128) to save memory.\n",
    "#\t•\tThis template includes an automatic batch-size fallback: it will try a list like [32, 16, 8, 4] and proceed with the first that fits.\n",
    "#\n",
    "#Expected output\n",
    "#\t•\tLogs from the frozen stage (accuracy typically rises quickly).\n",
    "#\t•\tLogs from the fine-tuning stage showing a modest improvement over frozen.\n",
    "#\t•\tA final print like:\n",
    "#{'transfer_learning_final_test_accuracy': 0.85, 'transfer_learning_test_loss': 0.72}\n",
    "#\t•\tFinal test accuracy should be higher than training from scratch on the same small dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13357f7b",
   "metadata": {},
   "source": [
    "## Discussion (answer in complete sentences)\n",
    "\n",
    "1. Compare LeNet and AlexNet design choices (kernel sizes, depth, FC layers). How do these affect compute and accuracy?\n",
    "2. Why does transfer learning typically outperform training from scratch on small datasets? Which layers would you fine-tune and why?\n",
    "3. If your AlexNet-like model underperforms, which two architecture or training changes would you try first, and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef8d619",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab 6 (Week 7) — Student v4"
  },
  "kernelspec": {
   "display_name": "CSB410",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
